{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/vaishrohan/anaconda2/lib/python2.7/site-packages/sklearn/ensemble/weight_boosting.py:29: DeprecationWarning: numpy.core.umath_tests is an internal NumPy module and should not be imported. It will be removed in a future NumPy release.\n",
      "  from numpy.core.umath_tests import inner1d\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import csv\n",
    "from datetime import datetime, timedelta\n",
    "from sklearn.datasets import make_regression\n",
    "from sklearn import linear_model\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.datasets import make_regression\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.ensemble import AdaBoostRegressor\n",
    "from sklearn.metrics import mean_absolute_error, r2_score\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "import matplotlib.pyplot as plt\n",
    "import statsmodels.api as sm\n",
    "import matplotlib\n",
    "import itertools\n",
    "from pylab import rcParams\n",
    "import pickle\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{1: 'mains_1', 2: 'mains_2', 3: 'oven_3', 4: 'oven_4', 5: 'refrigerator_5', 6: 'dishwaser_6', 7: 'kitchen_outlets_7', 8: 'kitchen_outlets_8', 9: 'lighting_9', 10: 'washer_dryer_10', 11: 'microwave_11', 12: 'bathroom_gfi_12', 13: 'electric_heat_13', 14: 'stove_14', 15: 'kitchen_outlets_15', 16: 'kitchen_outlets_16', 17: 'lighting_17', 18: 'lighting_18', 19: 'washer_dryer_19', 20: 'washer_dryer_20'}\n"
     ]
    }
   ],
   "source": [
    "mapping = {}\n",
    "for i in range(1,7):\n",
    "    file_path = 'low_freq/house_' + str(i) + '/labels.dat'\n",
    "    mapping[i] = {}\n",
    "    with open(file_path) as file:\n",
    "        for line in file:\n",
    "            mapping[i][int(line.split(' ')[0].strip())] = line.split(' ')[1].strip() + '_' + line.split(' ')[0].strip()\n",
    "print(mapping[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = {}\n",
    "for i in range(1,7):\n",
    "    file_path = 'low_freq/house_' + str(i) + '/channel_' + str(i) + '.dat'\n",
    "    df[i] = pd.read_csv(file_path , sep = ' ', names = ['TimeStamp', mapping[i][1]], dtype = {'TimeStamp': 'int64', mapping[i][1]:'float64'})\n",
    "    for j in range(2, len(mapping[i])+1):\n",
    "        curr_file_path =  'low_freq/house_' + str(i) + '/channel_' + str(j) + '.dat'\n",
    "        curr = pd.read_csv(curr_file_path , sep = ' ', names = ['TimeStamp', mapping[i][j]], dtype = {'TimeStamp': 'int64', mapping[i][j]:'float64'})\n",
    "        df[i] = pd.merge(df[i], curr, how='inner', on='TimeStamp')\n",
    "    df[i]['TimeStamp'] = df[i]['TimeStamp'].astype(\"datetime64[s]\")\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for i in range(1,7):\n",
    "    for j, row in df[i].iterrows():\n",
    "        df[i].at[j,'Year'] = row[0].year\n",
    "        df[i].at[j,'Month'] = row[0].month\n",
    "        df[i].at[j,'Day'] = row[0].day\n",
    "        df[i].at[j,'Hour'] = row[0].hour\n",
    "        df[i].at[j,'Minute'] = row[0].minute\n",
    "        df[i].at[j,'Seconds'] = row[0].second\n",
    "        if row[0].weekday() in [5,6] :\n",
    "            df[i].at[j, 'Holiday'] = 1\n",
    "        else:\n",
    "            df[i].at[j, 'Holiday'] = 0\n",
    "        if row[0].hour in [0,1,2,3,4,5,6,7,20,21,22,23]:\n",
    "            df[i].at[j, 'Peak Hour'] = 1\n",
    "        else:\n",
    "            df[i].at[j, 'Peak Hour'] = 0\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mapping[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#LinearRegressor\n",
    "\n",
    "result['Linear'] = {}\n",
    "for key , target in mapping[1].iteritems():\n",
    "    features = []\n",
    "    for key, value in mapping[1].iteritems():\n",
    "        if value != target:\n",
    "            features.append(value)\n",
    "    features.append('Day')\n",
    "    features.append('Hour')\n",
    "    features.append('Minute')\n",
    "    features.append('Seconds')\n",
    "    features.append('Holiday')\n",
    "    features.append('Peak Hour')\n",
    "    train_size = (80 *len(df[1]))/100\n",
    "    x_train = df[1][features][:train_size]\n",
    "    y_train = df[1][target][:train_size]\n",
    "    x_test = df[1][features][train_size:]\n",
    "    y_test = df[1][target][train_size:]\n",
    "\n",
    "    regr = linear_model.LinearRegression()\n",
    "    regr.fit(x_train, y_train)\n",
    "    y_pred_r = regr.predict(x_test)\n",
    "    result['Linear'][target] = []\n",
    "    result['Linear'][target].append(y_pred_r)\n",
    "    result['Linear'][target].append(mean_absolute_error(y_test,y_pred_r))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#RandomForestRegressor\n",
    "\n",
    "result['RandomForest'] = {}\n",
    "for key , target in mapping[1].iteritems():\n",
    "    features = []\n",
    "    for key, value in mapping[1].iteritems():\n",
    "        if value != target:\n",
    "            features.append(value)\n",
    "    features.append('Day')\n",
    "    features.append('Hour')\n",
    "    features.append('Minute')\n",
    "    features.append('Seconds')\n",
    "    features.append('Holiday')\n",
    "    features.append('Peak Hour')\n",
    "    train_size = (80 *len(df[1]))/100\n",
    "    x_train = df[1][features][:train_size]\n",
    "    y_train = df[1][target][:train_size]\n",
    "    x_test = df[1][features][train_size:]\n",
    "    y_test = df[1][target][train_size:]\n",
    "\n",
    "    regr = RandomForestRegressor(max_depth=2, random_state=0)\n",
    "    regr.fit(x_train, y_train)\n",
    "    y_pred_r = regr.predict(x_test)\n",
    "    result['RandomForest'][target] = []\n",
    "    result['RandomForest'][target].append(y_pred_r)\n",
    "    result['RandomForest'][target].append(mean_absolute_error(y_test,y_pred_r))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#RidgeRegressor\n",
    "\n",
    "result['Ridge'] = {}\n",
    "for key , target in mapping[1].iteritems():\n",
    "    features = []\n",
    "    for key, value in mapping[1].iteritems():\n",
    "        if value != target:\n",
    "            features.append(value)\n",
    "    features.append('Day')\n",
    "    features.append('Hour')\n",
    "    features.append('Minute')\n",
    "    features.append('Seconds')\n",
    "    features.append('Holiday')\n",
    "    features.append('Peak Hour')\n",
    "    train_size = (80 *len(df[1]))/100\n",
    "    x_train = df[1][features][:train_size]\n",
    "    y_train = df[1][target][:train_size]\n",
    "    x_test = df[1][features][train_size:]\n",
    "    y_test = df[1][target][train_size:]\n",
    "\n",
    "    regr = linear_model.Ridge(alpha=.5)\n",
    "    regr.fit(x_train, y_train)\n",
    "    y_pred_r = regr.predict(x_test)\n",
    "    result['Ridge'][target] = []\n",
    "    result['Ridge'][target].append(y_pred_r)\n",
    "    result['Ridge'][target].append(mean_absolute_error(y_test,y_pred_r))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#LassoRegressor\n",
    "\n",
    "result['Lasso'] = {}\n",
    "for key , target in mapping[1].iteritems():\n",
    "    features = []\n",
    "    for key, value in mapping[1].iteritems():\n",
    "        if value != target:\n",
    "            features.append(value)\n",
    "    features.append('Day')\n",
    "    features.append('Hour')\n",
    "    features.append('Minute')\n",
    "    features.append('Seconds')\n",
    "    features.append('Holiday')\n",
    "    features.append('Peak Hour')\n",
    "    train_size = (80 *len(df[1]))/100\n",
    "    x_train = df[1][features][:train_size]\n",
    "    y_train = df[1][target][:train_size]\n",
    "    x_test = df[1][features][train_size:]\n",
    "    y_test = df[1][target][train_size:]\n",
    "\n",
    "    regr = linear_model.Lasso(alpha=0.1)\n",
    "    regr.fit(x_train, y_train)\n",
    "    y_pred_r = regr.predict(x_test)\n",
    "    result['Lasso'][target] = []\n",
    "    result['Lasso'][target].append(y_pred_r)\n",
    "    result['Lasso'][target].append(mean_absolute_error(y_test,y_pred_r))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#BaysianRidgeRegressor\n",
    "\n",
    "result['Baysian'] = {}\n",
    "for key , target in mapping[1].iteritems():\n",
    "    features = []\n",
    "    for key, value in mapping[1].iteritems():\n",
    "        if value != target:\n",
    "            features.append(value)\n",
    "    features.append('Day')\n",
    "    features.append('Hour')\n",
    "    features.append('Minute')\n",
    "    features.append('Seconds')\n",
    "    features.append('Holiday')\n",
    "    features.append('Peak Hour')\n",
    "    train_size = (80 *len(df[1]))/100\n",
    "    x_train = df[1][features][:train_size]\n",
    "    y_train = df[1][target][:train_size]\n",
    "    x_test = df[1][features][train_size:]\n",
    "    y_test = df[1][target][train_size:]\n",
    "\n",
    "    regr = linear_model.BayesianRidge()\n",
    "    regr.fit(x_train, y_train)\n",
    "    y_pred_r = regr.predict(x_test)\n",
    "    result['Baysian'][target] = []\n",
    "    result['Baysian'][target].append(y_pred_r)\n",
    "    result['Baysian'][target].append(mean_absolute_error(y_test,y_pred_r))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mains_values = df[1]['mains_1'][train_size:]+df[1]['mains_2'][train_size:]\n",
    "oven_pred_values = result['RandomForest']['oven_3'][0]\n",
    "fig_size = plt.rcParams[\"figure.figsize\"]\n",
    "fig_size[0] = 14\n",
    "fig_size[1] = 7\n",
    "plt.rcParams[\"figure.figsize\"] = fig_size\n",
    "timeline = df[1]['TimeStamp'][train_size+62400:train_size+63400]\n",
    "plt.plot(timeline, mains_values[62400:63400], label=\"Mains\")\n",
    "plt.plot(timeline, oven_pred_values[62400:63400], label=\"Oven Predictions\")\n",
    "plt.title('Predicted Disaggregated Oven Consumption from Mains Consumption')\n",
    "plt.xlabel('Timestamp')\n",
    "plt.ylabel('Energy Consumption (Watts)')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "oven_actual_values = df[1]['oven_3'][train_size:]\n",
    "oven_pred_values = result['RandomForest']['oven_3'][0]\n",
    "fig_size = plt.rcParams[\"figure.figsize\"]\n",
    "fig_size[0] = 14\n",
    "fig_size[1] = 7\n",
    "plt.rcParams[\"figure.figsize\"] = fig_size\n",
    "timeline = df[1]['TimeStamp'][train_size+62400:train_size+63400]\n",
    "plt.plot(timeline, oven_actual_values[62400:63400], label=\"Oven Actual\")\n",
    "plt.plot(timeline, oven_pred_values[62400:63400], label=\"Oven Predictions\")\n",
    "plt.title('Actual Consumption vs Predicted Consumption for Oven')\n",
    "plt.xlabel('Timestamp')\n",
    "plt.ylabel('Energy Consumption (Watts)')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "objects = []\n",
    "performance = []\n",
    "timestamp = 62800\n",
    "mains_consumption = str(df[1]['mains_1'][timestamp] + df[1]['mains_2'][timestamp])\n",
    "for key , target in mapping[1].iteritems():\n",
    "    if target != 'mains_1' and target != 'mains_2' and result['RandomForest'][target][0][timestamp] > 2:\n",
    "        objects.append(target)\n",
    "        performance.append(result['RandomForest'][target][0][timestamp])\n",
    "\n",
    "y_pos = np.arange(len(objects))\n",
    "\n",
    "barlist = plt.bar(y_pos, performance, align='center', alpha=0.5)\n",
    "plt.xticks(y_pos, objects)\n",
    "plt.ylabel('Energy (Watts)')\n",
    "plt.xlabel('Appliance Name')\n",
    "plt.title('Energy Disaggregated at time : ' + str(df[1]['TimeStamp'][timestamp]) + ' where Total Energy Consumption = 377.18')\n",
    "barlist[0].set_color('r')\n",
    "barlist[1].set_color('b')\n",
    "barlist[2].set_color('g')\n",
    "barlist[3].set_color('y')\n",
    "barlist[4].set_color('k')\n",
    "barlist[5].set_color('m')\n",
    "barlist[6].set_color('c')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output = {}\n",
    "algorithms = ['RandomForest' , 'Linear' , 'Ridge' , 'Lasso', 'Baysian']\n",
    "updated_objects = objects\n",
    "updated_objects.append('oven_3')\n",
    "updated_objects.append('oven_4')\n",
    "for app in updated_objects :\n",
    "    output[app] = {}\n",
    "    for algo in algorithms:\n",
    "        output[app][algo] = round(result[algo][app][1],5)\n",
    "        \n",
    "display(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num = 0\n",
    "den = 0\n",
    "final = {}\n",
    "for algo in algorithms:\n",
    "    for key , target in mapping[1].iteritems():\n",
    "        actual_values = df[1][target][train_size:]\n",
    "        pred_values = result[algo][target][0]\n",
    "        for i in range(0, len(actual_values)):\n",
    "            if target != 'mains_1' and target != 'mains_2':\n",
    "                num += abs(pred_values[i] - actual_values[train_size+i])\n",
    "            else:\n",
    "                den += actual_values[train_size+i]\n",
    "    correctness = 1- (num / (2*den))\n",
    "    final[algo] = correctness\n",
    "\n",
    "print(final)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
